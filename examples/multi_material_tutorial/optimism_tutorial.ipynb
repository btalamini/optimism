{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6356bf65",
   "metadata": {},
   "source": [
    "# Tutorial: a multi-material problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ebec7",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this problem, we'll subject a rectangular slab to plane strain uniaxial tension. As shown in the figure, the slab is made of two equal-size layers made of different materials. One material will use a hyperelastic material model, while the other will use a $J_2$ plasticity model. The slab will be loaded by applying an extensional displacement $d$ to the top edge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60dcbd2",
   "metadata": {},
   "source": [
    "![diagram](./diagram2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045899d7",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp # as in \"old\" numpy, to distinguish it from Jax's numpy.\n",
    "\n",
    "from optimism.JaxConfig import *\n",
    "from optimism import EquationSolver\n",
    "from optimism import FunctionSpace\n",
    "from optimism import Interpolants\n",
    "from optimism.material import J2Plastic\n",
    "from optimism.material import Neohookean\n",
    "from optimism import Mechanics\n",
    "from optimism import Mesh\n",
    "from optimism import Objective\n",
    "from optimism import QuadratureRule\n",
    "from optimism import SparseMatrixAssembler\n",
    "from optimism import VTKWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15441e66",
   "metadata": {},
   "source": [
    "## Set up the mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da642525",
   "metadata": {},
   "source": [
    "As in any finite element code, first we need to discretize the geometry of the body with a mesh. Optimism can read in meshes from the Exodus II format, but it also provides utilities for generating structured meshes. The structured mesh route is often best for for simple problems like this one. Let's generate a rectangular mesh with width $w = 0.1$ and length $L = 1.0$. We'll also specify that it has 5 nodes in the $x$-direction (hence 4 elements) and 15 nodes in the $y$-direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4938c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the mesh\n",
    "w = 0.1\n",
    "L = 1.0\n",
    "nodesInX = 5 # must be odd for element boundaries to contain material boundary\n",
    "nodesInY = 15\n",
    "xRange = [0.0, w]\n",
    "yRange = [0.0, L]\n",
    "mesh = Mesh.construct_structured_mesh(nodesInX, nodesInY, xRange, yRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b23e4",
   "metadata": {},
   "source": [
    "The mesh object has an attribute called `blocks` which groups elements together to specify different materials on them. Let's see what blocks our mesh has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219257f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'block_0': DeviceArray([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,\n",
      "              12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,\n",
      "              24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
      "              36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
      "              48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
      "              60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "              72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "              84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
      "              96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "             108, 109, 110, 111], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "print(mesh.blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe9f12",
   "metadata": {},
   "source": [
    "`blocks` is a standard Python dictionary object (i.e. a `dict`), where the keys are strings that lets us give meaningful names to the element blocks. The values are Jax-numpy arrays that contain the indices of the elements in the block. The `construct_structured_mesh` function returns a mesh with just one block. We want two equal-sized blocks for our problem like in the figure, so let's modify the mesh.\n",
    "\n",
    "First, we'll define a simple helper function that takes in the vertices of a triangular element and returns the coordinates of the centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77813b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_centroid(vertices):\n",
    "    return np.average(vertices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d807f",
   "metadata": {},
   "source": [
    "We'll loop over the element node connectivity table, which is the `mesh.conns` object, extract the coordinates of its vertices, and use the `triangle_centroid` object on them to determine if the element is in the left or right layer. We will store the results in a list called `blockIds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c7dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the block IDs of all elements to a dummy value (-1)\n",
    "blockIds = -1*onp.ones(Mesh.num_elements(mesh), dtype=onp.int64)\n",
    "\n",
    "for e, t in enumerate(mesh.conns):\n",
    "    vertices = mesh.coords[t,:]\n",
    "    if triangle_centroid(vertices)[0] < w/2:\n",
    "        blockIds[e] = 0\n",
    "    else:\n",
    "        blockIds[e] = 1\n",
    "# check that every element has gotten an ID\n",
    "assert(onp.all(blockIds != -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c5019",
   "metadata": {},
   "source": [
    "This will mark an element as block 0 if it's centroid is on the left hand side of the slab, and as block 1 if it's on the other side. Now, let's make the `dict` that we want to attach to the mesh object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8ce025",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = {'left layer': np.flatnonzero(np.array(blockIds) == 0),\n",
    "          'right layer': np.flatnonzero(np.array(blockIds) == 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f443e0",
   "metadata": {},
   "source": [
    "Now we can make use of a function that takes in the original mesh (with one block) and the block IDs we just created, and returns a new mesh that is the same as the old one except that the blocks have been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5c94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh.mesh_with_blocks(mesh, blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f85f8a",
   "metadata": {},
   "source": [
    "Let's check to make sure this process worked. To do this, we'll make use of optimism's output facilities. Optimism provides a class called `VTKWriter`, that, as the name suggests, writes data to VTK files which can be visualized in ParaView (and several other visualization tools). First, we instantiate a VTKWriter object, giving it the base of the filename (the name that will be suffixed with the \".vtk\" extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da768ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = VTKWriter.VTKWriter(mesh, baseFileName='check_problem_setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f340c",
   "metadata": {},
   "source": [
    "Next, we can start adding fields. In this case, we only have one field - the block ID numbers - which is a scalar field of integer type. Finally, once our data is loaded into the writer, we call the `write()` method to tell it to write the VTK file to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b50965",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_cell_field(name='block_id', cellData=blockIds,\n",
    "                      fieldType=VTKWriter.VTKFieldType.SCALARS,\n",
    "                      dataType=VTKWriter.VTKDataType.INT)\n",
    "writer.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee4b9d",
   "metadata": {},
   "source": [
    "This is what we get when we open the file `check_problem_setup.vtk` in ParaView and visualize the `block_id` field. If you try it, you should see something similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4fb70",
   "metadata": {},
   "source": [
    "![paraview shwoing blocks in mesh](blocks_elements.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15ed2a",
   "metadata": {},
   "source": [
    "The left layer is blue (element block 0) and the right layer is red (element block 1). Success! This is what were shooting for. (The particular colors may be different in your ParaView installation depending on the color palate chosen for contour plots, but the spatial layout of the blocks should be the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc1328",
   "metadata": {},
   "source": [
    "We're going to make one more modification to the mesh. Looking again at the problem setup figure, we can see that we need to apply essential boundary conditions on the bottom, left, and top boundary edges of the slab. We must create node sets that group the nodes on these edges together so that we can set the boundary condtions on them later. Similar to the `blocks` attribute, `mesh` has a `nodeSets` attribute that is a dictionary mapping names of node sets to the indices of the nodes in the set. We'll make the node sets we need by performing range queries over the nodal coordinates, storing the indices of the nodes on the left edge under the key \"left\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50df5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeTol = 1e-8\n",
    "nodeSets = {'left': np.flatnonzero(mesh.coords[:,0] < xRange[0] + nodeTol),\n",
    "            'right': np.flatnonzero(mesh.coords[:,0] > xRange[1] - nodeTol),\n",
    "            'bottom': np.flatnonzero(mesh.coords[:,1] < yRange[0] + nodeTol),\n",
    "            'top': np.flatnonzero(mesh.coords[:,1] > yRange[1] - nodeTol)}\n",
    "\n",
    "# create a copy of the mesh that has the nodeSets in it\n",
    "mesh = Mesh.mesh_with_nodesets(mesh, nodeSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02948e6",
   "metadata": {},
   "source": [
    "## Build the discrete function space\n",
    "The next step is to create a representation of the discrete function space in which we will search for a solution. This object will also help us do things like interpolate our fields and do calculus on them. The first ingredient we need is a quadrature rule. In optimism, quadrature rules are specified by the highest degree polynomial that they can exactly integrate. A smart way to do this is to choose it in relation to $p$, the polynomial degree of our interpolation, which we can obtain like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6cc7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mesh.parentElement.degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bbbb95",
   "metadata": {},
   "source": [
    "In the linearized theory of quasi-static solid mechanics, the natural trial/test function space is $H^1$, because the operator contains inner products of gradients of the displacement. Since our interpolation uses polynomials of degrees up to $p$, the displacement gradient is of degree $p-1$, and the inner product of gradients is of degree $2(p-1)$. Thus, we choose this as our quadrature rule precision to avoid under-integrating our operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4e827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function space\n",
    "quadRule = QuadratureRule.create_quadrature_rule_on_triangle(degree=2*(p - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b967ae4",
   "metadata": {},
   "source": [
    "The benefit of specifying our quadrature rule in this way is that if we later decide to modify the mesh to use higher-order elements, the quadrature rule will be updated automatically. This helps keep us out of trouble with hourglassing problems. Note that our operator is *nonlinear*, so the quadrature rule won't integrate it exactly, but the accuracy requirement of the linearized theory is still a good rule of thumb.\n",
    "\n",
    "With the quadrature rule and the mesh, we can now construct the function space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc72db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FunctionSpace.construct_function_space(mesh, quadRule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570688e",
   "metadata": {},
   "source": [
    "The function space holds data like the values of shape functions and their gradients at all of the quadrature points in the mesh. We'll see this object again later when we set up our energy function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244059e7",
   "metadata": {},
   "source": [
    "Now we're going to register the essential boundary conditions so that the optimism solvers will know how to deal with them. This is done with an `EssentialBC` object. Each `EssentialBC` represents a boundary condition on one field component of a node set. As en example, let's create one to represent the $x$-component displacement boundary condition on the nodes of the left edge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8df8bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebcLeft = FunctionSpace.EssentialBC(nodeSet='left', component=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f25c8",
   "metadata": {},
   "source": [
    "This is one boundary condition; we have three essential boundary conditions in total to apply. The thing to do is to collect them all in a list. So the code looks like it would in a real application, we'll ignore the `ebcLeft` object above and create all of the essential boundary conditions in one statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f61e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebcs = [FunctionSpace.EssentialBC(nodeSet='left', component=0),\n",
    "        FunctionSpace.EssentialBC(nodeSet='bottom', component=1),\n",
    "        FunctionSpace.EssentialBC(nodeSet='top', component=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac4490",
   "metadata": {},
   "source": [
    "Next, we create a `DofManager` object. What is this for? It's a class to help us index into our nodal arrays, keeping track of which degrees of freedom have essential boundary conditions, and which are unrestrained (hence are unknowns to be solved for). Its usage will become clearer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f306eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dofManager = FunctionSpace.DofManager(fs, dim=2, EssentialBCs=ebcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0291001",
   "metadata": {},
   "source": [
    "The argument `dim` tells the `dofManager` what the vector dimension is of the unknowns (and hence the number of columns in the discrete nodal unknown arrays). Our unknowns are displacements, and we're working in 2D, so we set it to 2.\n",
    "\n",
    "We use the vis tools again to check that we've specified the essential boundary conditions correctly. First, we'll use a little trick to turn the boundary conditions into a viewable nodal field. We'll use an attribute of the `DofManager` class called `isBc`, which is a boolean array of shape `fieldShape` that indicates whether each DOF has an essential boundary condition. We cast this to an array of integers (more precisely, the `int64` type in numpy) which gives them values of 0 (for no essential boundary condition) or 1 (for an essential boundary condition) which can be plotted in ParaView. The `dataType` argument is different from the `add_nodal_field` call for the element block ID, since that was a *scalar* field. For boundary conditions, we want it to be a *vector* field (one component for each displacement component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea61275",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcs = np.array(dofManager.isBc, dtype=np.int64)\n",
    "writer.add_nodal_field(name='bcs', nodalData=bcs, fieldType=VTKWriter.VTKFieldType.VECTORS,\n",
    "                       dataType=VTKWriter.VTKDataType.INT)\n",
    "writer.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3cc28d",
   "metadata": {},
   "source": [
    "Note that `writer` still refers to the same `VTKWriter` object as before. A VTKWriter object is always associated with the same filename, so when we add a new field and then call the `write()` method, it will overwrite the previous VTK file. Indeed, if you open `check_problem_steup.vtk`, you'll see that it now contains two output fields, \"block_id\" and \"bcs\".\n",
    "\n",
    "Contour plots of the $x$- and $y$-components of the \"bcs\" field are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df5456",
   "metadata": {},
   "source": [
    "![contour plots of boundary condition fields](boundary_conditions.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb692616",
   "metadata": {},
   "source": [
    "The first plot shows all nodes with boundary conditions on the $x$ component of the displacement. We see that the left edge has a value of 1 (which means that the boundary condition flag is \"True\" there), and every other node has a value of 0, which means they are unrestrained. This is exactly what we want. The $y$ component plot also confirms that the top and bottom edges correctly have their boundary conditions. Of course, the top edge has an *inhomogeneous* boundary condition. We'll enforce the actual value of this boundary condition later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffeee71",
   "metadata": {},
   "source": [
    "## Material models\n",
    "Next, we instantiate the material models for the slab. For the left side, we'll choose a Neo-Hookean material. Material models in optimism take their material parameters in the form of a dictionary. For Neo-Hookean, the required parameters are the elastic modulus and the Poisson's ratio (both taken about the undeformed state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f7d7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the material model for the left side\n",
    "props = {'elastic modulus': 5.0,\n",
    "         'poisson ratio': 0.25}\n",
    "leftMaterialModel = Neohookean.create_material_model_functions(props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d32097",
   "metadata": {},
   "source": [
    "TODO: The property names are not documented yet. For now, you can find them by inspecting the code in `optimism/materials`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4acb7",
   "metadata": {},
   "source": [
    "Now we'll instantiate the other material model for the right-hand side. We'll pick a $J_2$ plasticity model, which is a bit more interesting (and thus has more parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5d64680",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 10.0\n",
    "nu = 0.25\n",
    "Y0 = 0.01*E\n",
    "H = E/100\n",
    "props = {'elastic modulus': E,\n",
    "         'poisson ratio': nu,\n",
    "         'yield strength': Y0,\n",
    "         'hardening model': 'linear',\n",
    "         'hardening modulus': H}\n",
    "rightMaterialModel = J2Plastic.create_material_model_functions(props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34971c24",
   "metadata": {},
   "source": [
    "The meaning of the parameters is clear from the keys. There are several hardening models currently available, such as linear hardening, a version of power law hardening, and the Voce exponential saturation law. We'll keep it simple and just use linear hardening.\n",
    "\n",
    "For multi-material simulations, we must create a dictionary of each material that maps the name of each element block to the material model object for that block, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6040db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "materialModels = {'left layer': leftMaterialModel, 'right layer': rightMaterialModel}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8be55",
   "metadata": {},
   "source": [
    "## Write the energy function to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47989532",
   "metadata": {},
   "source": [
    "Numerical solutions to PDEs are obtained in optimism by minimizing an objective function, which may be thought of intuitively as en energy. In fact, for hyperelastic materials, the objective function *is* the total energy. For history-dependent materials, one can often write an incremental functional that is minimized by the displacement field that carries the body from one discrete time step to the next. We're going to write the function for our problem now.\n",
    "\n",
    "There is a tool in the `Mechanics` module that will do most of the work for us. Let's call it first and explain its output afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "637b03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# mechanics functions\n",
    "mechanicsFunctions = Mechanics.create_multi_block_mechanics_functions(\n",
    "    fs, mode2D=\"plane strain\", materialModels=materialModels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c60c2d",
   "metadata": {},
   "source": [
    "The `create_multi_block_mechanics_functions` writes some functions for us to help write the problem in the right form. The most important part of the output is `mechanicsFunctions.compute_strain_energy(...)`, which writes all the loops over the blocks, elements, and quadrature points that you would need to compute the energy from the nodal displacements. (Now we finally see the `FunctionSpace` object `fs` in action). To be able to write these loops, `create_multi_block_mechanics_functions` needs to know we are working in plane strain, and it needs to use the material models as well. \n",
    "\n",
    "The `mechanicsFunctions.compute_strain_energy(...)` function is invoked like this:\n",
    "```python\n",
    "mechanicsFunctions.compute_strain_energy(U, internalVariables)\n",
    "```\n",
    "where `U` is the array of the degrees of freedom (the nodal displacements), and `internalVariables` is an array of the internal variables at every quadrature point; that is, it has shape `(ne, neqp, nint)`, with `ne` being the number of elements, `neqp` the number of quadrature points per element, and `nint` the number of internal variables for the material model.  (*NOTE: For multi-material simulations, this is currently sized such that `nint` is the maximum number of internal variables over all materials, so that the array is padded for materials using fewer internal variables. We may remove this restriction in the future to improve memory efficiency*).\n",
    "Under the hood, this function tells optimism everything it needs to solve the problem through automatic differentiation. The derivative of `mechanicsFunctions.compute_strain_energy(U, internalVariables)` with respect to the nodal displacements `U` gives the residual function, and the Hessian yields the stiffness matrix (more precisely, the Hessian-vector product is evaluated to give the action of the stiffness matrix on a vector). All of these derivatives are taken automatically by optimism in the solver, so we don't need to worry about them at the application level.\n",
    "\n",
    "All of the minimization solvers in optimism require the objective function to have a signature like this:\n",
    "```python\n",
    "energy_function(Uu, p)\n",
    "```\n",
    "where `Uu` is the array of unknowns, and `p` is called the parameter set. The parameter set essentially holds all of the information that is needed to specify the problem but *isn't* the set of unknowns. These are things like values of the boundary conditions and the internal variables, as well as some other categories. We need to cast our energy function in this form. Let's write it like this and work out what the intervening steps must be:\n",
    "\n",
    "```python\n",
    "def energy_function(Uu, p):\n",
    "    U = create_field(Uu, p)\n",
    "    internalVariables = p.state_data\n",
    "    return mechanicsFunctions.compute_strain_energy(U, internalVariables)\n",
    "```\n",
    "On the first line, we use the parameter set to extend the array of unknown displacements to the full array of nodal displacements. This means we need to fill in the values of the inhomogeneous boundary conditions, which is what we'll do when we implement `create_field(...)`. Next, we pull out the internal variables from the parameter set. Finally, we use the canned `compute_strain_energy(...)` function with these variables in order to compute the total energy.\n",
    "\n",
    "The inhomogeneous boundary condition part is handled like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "379d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to fill in nodal values of essential boundary conditions\n",
    "def get_ubcs(p):\n",
    "    appliedDisp = p[0]\n",
    "    EbcIndex = (mesh.nodeSets['top'], 1)\n",
    "    V = np.zeros_like(mesh.coords).at[EbcIndex].set(appliedDisp)\n",
    "    return dofManager.get_bc_values(V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b6254",
   "metadata": {},
   "source": [
    "We will store the applied displacement in the first slot of the parameter set, `p[0]`. In line 4 above we extract it. Then we make an array of the same size as the nodal displacements, set it to zero, and replace the values in the DOFs on the top edge with the value of the applied displacement.\n",
    "\n",
    "Now we can write the `create_field(...)` function shown above in the proposed `energy_function(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a23d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to go from unknowns to full DoF array\n",
    "def create_field(Uu, p):\n",
    "    Uebc = get_ubcs(p)\n",
    "    return dofManager.create_field(Uu, Uebc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab84ba9",
   "metadata": {},
   "source": [
    "The `create_field(...)` method in the `dofManager` takes in the unknown displacements `Uu` and an array of the same size with the values of the essential boundary conditions `Uebc` and packages them up together to create an array of all DOF values. The pieces are finally in place to define the energy function for our problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ebd34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the energy to minimize\n",
    "def energy_function(Uu, p):\n",
    "    U = create_field(Uu, p)\n",
    "    internalVariables = p[1]\n",
    "    return mechanicsFunctions.compute_strain_energy(U, internalVariables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d271df0",
   "metadata": {},
   "source": [
    "The slot `p[1]` is always reserved for the internal variable field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815942c",
   "metadata": {},
   "source": [
    "## Set up the optimization solver\n",
    "We have an objective function - `energy_function(...)`, which we will hand to an optimization routine that will find the unknowns displacements. In this section, we specficy which optimization solver we want to use, and tell it how to work. \n",
    "\n",
    "We will use the Steighaug trust region method. This method uses linear conjugate gradient iterations as part of its algorithm, which in turn need to be preconditioned in order to be effective. Currently, the only available preconditioner in optimism is a Cholesky factorization of the stiffness matrix. We need to intruct the solver how to assemble the stiffness matrix like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "396fcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell objective how to assemble preconditioner matrix\n",
    "def assemble_sparse_preconditioner_matrix(Uu, p):\n",
    "    U = create_field(Uu, p)\n",
    "    internalVariables = p[1]\n",
    "    elementStiffnesses = mechanicsFunctions.compute_element_stiffnesses(U, internalVariables)\n",
    "    return SparseMatrixAssembler.assemble_sparse_stiffness_matrix(\n",
    "        elementStiffnesses, mesh.conns, dofManager)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbde23",
   "metadata": {},
   "source": [
    "We see once again that `mechanicsFunctions` provides a helper function. In this case, the function `compute_element_stiffnesses(...)` takes the same inputs as the energy function, but instead of returning the total energy, it returns an array containing the stiffness matrix for each element. The elemental stiffness matrices are the Hessians of the total energy in each element, and automatic differentiation is again used to perform this calculation. The `assemble_sparse_stiffness_matrix(...)` function takes these elemental stiffness matrices and contructs the system's stiffness matrix using a sparse matrix data structure (from SciPy). We tell the solver how to use this capability by building something called a `PrecondStrategy`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aeca02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precondStrategy = Objective.PrecondStrategy(assemble_sparse_preconditioner_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b621c",
   "metadata": {},
   "source": [
    "Finally, we can specify custom settings for the solver is we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01556d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver settings\n",
    "solverSettings = EquationSolver.get_settings(use_preconditioned_inner_product_for_cg=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf08b3f",
   "metadata": {},
   "source": [
    "## Solve!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e405b",
   "metadata": {},
   "source": [
    "Parameter sets are constructed by calling the `Params` function in the `Objective` module. This is to help organize them in certain categories that the solver needs to be aware of, such as which ones have derivatives taken with respect to inside the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c18895d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembling preconditioner 0\n",
      "min, max diagonal stiffness =  0.9999999999999998 1.0000000000000002\n",
      "Factorizing preconditioner\n",
      "num warm start cg iters =  1\n",
      "Assembling preconditioner 0\n",
      "min, max diagonal stiffness =  0.9875365254464693 1.0110599625088337\n",
      "Factorizing preconditioner\n",
      "\n",
      "Initial objective, residual =  3.963903970114089e-05 1.5580526760827706e-05\n",
      "obj= -1.47133414e-10 , model obj= -1.47130159e-10 , res=  5.10352716e-10 , model res=  1.04258556e-20 , cg iters=   1 , tr size=          2.0 ,  interior  , accepted=  True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize unknown displacements to zero\n",
    "Uu = np.zeros(dofManager.get_unknown_size())\n",
    "\n",
    "# set initial values of parameters\n",
    "appliedDisp = 0.0\n",
    "state = mechanicsFunctions.compute_initial_state()\n",
    "p = Objective.Params(appliedDisp, state)\n",
    "    \n",
    "# Construct an objective object for the equation solver to work on\n",
    "objective = Objective.ScaledObjective(energy_function, Uu, p, precondStrategy=precondStrategy)\n",
    "    \n",
    "# increment the applied displacement\n",
    "appliedDisp = L*0.01\n",
    "p = Objective.param_index_update(p, 0, appliedDisp)\n",
    "\n",
    "# Find unknown displacements by minimizing the objective\n",
    "Uu = EquationSolver.nonlinear_equation_solve(objective, Uu, p, solverSettings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f1ac5",
   "metadata": {},
   "source": [
    "## Post-process\n",
    "The last step is to write out the simulation results so that we can use them. We've already seen a few examples of generating VTK output. Let's create another `VTKWriter` for the simulation results. Adding the displacement field is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5ac29dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write solution data to VTK file for post-processing\n",
    "writer = VTKWriter.VTKWriter(mesh, baseFileName='uniaxial_two_material')\n",
    "\n",
    "U = create_field(Uu, p)\n",
    "writer.add_nodal_field(name='displacement', nodalData=U, \n",
    "                       fieldType=VTKWriter.VTKFieldType.VECTORS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97ee7c",
   "metadata": {},
   "source": [
    "Let's also show an example of plotting quadrature field data. A commonly needed output is the stress field. We make use of another function in `mechanicsFunctions` to help us. However, before we write out any quadrature field data, we should update the internal variables. Currently, `state` still holds the initial values of the internal variables (before the load step was taken). That is, the solver finds the equilibrium displacement field, but doesn't change `state` in place. This is again due to Jax's functional programming paradigm. The following function call returns the updated internal variables using the new equilibrium displacement field and the old internal variables as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2926f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the state variables in the new equilibrium configuration\n",
    "state = mechanicsFunctions.compute_updated_internal_variables(U, p.state_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea016b",
   "metadata": {},
   "source": [
    "We make use of another of the `mechanicsFunctions` member functions to get the stress field, using the updated internal variables. Note that we don't pay the cost of iteratively solving the history-dependent material model response again. This function expects that the internal variables are already updated when it is called, and simply uses theses values in the evaluation of the material model energy density functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc41d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "energyDensities, stresses = mechanicsFunctions.compute_output_energy_densities_and_stresses(\n",
    "    U, state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cae332",
   "metadata": {},
   "source": [
    "As the left-hand side of this assignment implies, the scalar energy density field (at every quadrature point) is returned in addition to the stresses. In fact, only the scalar-valued energy density function for each material is implemented in each material model. The stress field is the derivative of the energy density function with respect to the displacement gradient, and optimism uses Jax's automatic differentiation to compute this derivative. When computing this derivative, evaluating the energy density at the same time is essentially free, so the above function computes them both.\n",
    "\n",
    "The `stresses` array contains the stress tensor at every quadrature point of every element. There is no interpolation associated with a quadrature field, so in order to visualize the stresses, one must be created, either on the application side or in the visualization software, if it has this capability. One simple way to accomplish this is to compute element-wise averages of the quadrature field and plot it as a cell-based field (instead of a nodal field). Optimism provides a method to do this called `FunctionSpace.project_quadrature_field_to_element_field(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55774221",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellStresses = FunctionSpace.project_quadrature_field_to_element_field(fs, stresses)\n",
    "writer.add_cell_field(name='stress', cellData=cellStresses,\n",
    "                      fieldType=VTKWriter.VTKFieldType.TENSORS)\n",
    "\n",
    "writer.write()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b4a7e",
   "metadata": {},
   "source": [
    "This concludes the tutorial. As an enhancement, the load stepping part above can be wrapped in a loop that will compute the response over multiple time steps. Note that before moving to the next time step, you should update the internal variables in the parameter set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fcb6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the state variables in the new equilibrium configuration\n",
    "p = Objective.param_index_update(p, 1, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782062d0",
   "metadata": {},
   "source": [
    "You can look at other example simulations to see how to do this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d350b21f4b10b49869f084214b140616e7efdffc14f312bd80d7753c6ae8d888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
